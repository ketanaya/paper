\documentclass[uplatex,a4j,11pt,dvipdfmx]{ujreport}

\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{enumerate}
\usepackage{fancyvrb}
\usepackage{fvextra}
\usepackage{mdframed}
\makeatletter
\def\kcharparline#1{
    \newcounter{chr}
    \setcounter{chr}{#1}
    \@tempdima=\linewidth
    \advance\@tempdima by-\value{chr}zw
    \addtocounter{chr}{-1}
    \divide\@tempdima by \value{chr}
    \advance\kanjiskip by\@tempdima
    \advance\parindent by\@tempdima}
\def\lineparpage#1{
    \baselineskip=\textheight
    \divide\baselineskip by #1}
\makeatother


\renewcommand{\bibname}{参考文献}

\begin{document}

\kcharparline{40} % 一行の文字数
\lineparpage{25}  % 一頁の行数


\title{卒業論文 \\
日経平均株価の時系列分析}
\author{
関西学院大学 商学部 \\
26022435 宮崎綾平% <--ここに学生番号と氏名を入れる
}
\date{2025年4月7日} % <--ここに作成日を入れる. 
%\date{\today} % 


\maketitle % タイトルページの作成

\tableofcontents % 目次の作成

\chapter{はじめに}

()

\chapter{現状分析(仮)} %<--ここに章のタイトルを入れる
この章では取得した日経平均株価のデータについての〜
\section{データの取得} % <--ここに節のタイトルを入れる
本研究で取得するデータはRのquantmodパッケージを使って以下のコードにより取得している。


\begin{Verbatim}[fontsize=\small, baselinestretch=0.9, frame=single]
> nikkei <- getSymbols(Symbols = "^N225", 
                       src = "yahoo",
                       from = "2015-01-01",
                       to = "2024-12-31",
                       auto.assign = FALSE)
\end{Verbatim}

\section{データの前処理}
まずはデータの前処理を行う。以下で粗データについて確認する。
\begin{Verbatim}[fontsize=\small, baselinestretch=0.9, frame=single]
> head(nikkei)
           N225.Open N225.High N225.Low N225.Close N225.Volume N225.Adjusted
2015-01-05  17325.68  17540.92 17219.22   17408.71   116500000      17408.71
2015-01-06  17101.58  17111.36 16881.73   16883.19   166000000      16883.19
2015-01-07  16808.26  16974.61 16808.26   16885.33   138600000      16885.33
2015-01-08  17067.40  17243.71 17016.09   17167.10   140600000      17167.10
2015-01-09  17318.74  17342.65 17129.53   17197.73   155200000      17197.73
2015-01-13  16970.88  17087.71 16828.27   17087.71   149200000      17087.71
\end{Verbatim}

粗データには「始値、高値、安値、終値、売買高、調整後終値」の列が存在する。本研究では終値を対象として分析を行う。以下で終値の列だけを抽出し、summary()でデータを確認する。なお、21個の欠測値が確認できるが、全て祝日で取引が行われていない日のデータであるため、na.omit()を使い除去する。



\begin{Verbatim}[fontsize=\small, baselinestretch=0.9, frame=single]
> nikkei_cl <- Cl(nikkei)
> summary(nikkei_cl)
     Index              N225.Close   
 Min.   :2015-01-05   Min.   :14952  
 1st Qu.:2017-07-07   1st Qu.:20013  
 Median :2019-12-14   Median :22823  
 Mean   :2019-12-27   Mean   :24832  
 3rd Qu.:2022-06-28   3rd Qu.:28451  
 Max.   :2024-12-30   Max.   :42224  
                      NA's   :21     
> nikkei_cl <- na.omit(nikkei_cl)
\end{Verbatim}

\section{データの時系列プロット}


図 \ref{fig:nikkei-cl} は、データの時系列プロットを描き、終値の変化を捉えたものである。
大きく値が変化している部分について、原因と推測される要因を挙げる。周期性はない。

\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\linewidth]{figures/nikkei_plot}
\caption{日経平均株価(終値)の推移} 
\label{fig:nikkei-cl} 
\end{figure}

\section{時系列データの自己相関}

図 \ref{fig:acf} は、データの自己相関をプロットしたものである。詳細な自己相関係数についても確認できる。(ここに考察)
\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\linewidth]{figures/acf}
\caption{日経平均株価(終値)の自己相関} 
\label{fig:acf} 
\end{figure}

\begin{Verbatim}[fontsize=\small, baselinestretch=0.9, frame=single]
> acf(nikkei_cl, plot = FALSE)

Autocorrelations of series ‘nikkei_cl’, by lag

    0     1     2     3     4     5     6     7     8     9    10    11    12 
1.000 0.997 0.994 0.992 0.989 0.986 0.984 0.981 0.979 0.976 0.974 0.972 0.969 
   13    14    15    16    17    18    19    20    21    22    23    24    25 
0.967 0.964 0.962 0.960 0.957 0.955 0.953 0.951 0.949 0.947 0.945 0.943 0.941 
   26    27    28    29    30    31    32    33 
0.939 0.937 0.935 0.933 0.931 0.929 0.927 0.924 
\end{Verbatim}

\chapter{平方根フィルタを用いた非定常時系列データの構成成分分解(仮)}

\section{decompについて(仮)}
(decompをやる目的)、を検証するために本研究ではTIMSACパッケージのdecomp関数を使用する。decomp関数とは()を行うための関数である。
具体的には以下のモデル式を使用する


\begin{equation}
y(t) = T(t) + AR(t) + S(t) + TD(t) + W(t)
\end{equation} 

ここで、T(t)はトレンド成分、AR(t)はAR成分、S(t)は季節成分、TD(t)は曜日効果成分、W(t)は観測ノイズである。
なお, これらは \cite{timsac} を参照している。
今回のデータはxtsオブジェクトのため〜なため、季節成分は除外して考える。また、曜日効果成分も〜という理由から除外して考える。
次にトレンド成分、AR成分の次数を決定するために、AIC(赤池情報量基準, Akaike's Information Criterion)を用いる。(AICの説明)
ここで、timsacパッケージを用いて、トレンド成分の次数を1,2,3、AR成分の次数を1~7に設定し、全ての組み合わせのAICを求めた。これらの組み合わせの中で最もAICが小さい
モデルを採用する。
\begin{Verbatim}[fontsize=\small, baselinestretch=0.9, frame=single]
    > library(timsac)
    > y <- nikkei_cl
    > 
    > for (m1 in 1:3) {
    +   for (m2 in 1:7) {
    +     k <- 0
    +     
    +     fit <- try(
    +       decomp(
    +         y,
    +         trend.order    = m1,
    +         ar.order       = m2,
    +         seasonal.order = k,
    +         plot           = FALSE
    +       ),
    +       silent = TRUE
    +     )
    +     
    +     if (inherits(fit, "try-error")) {
    +       cat("[ERROR]",
    +           "trend.order =", m1,
    +           "ar.order =", m2,
    +           "seasonal.order =", k,
    +           "AIC = NA\n")
    +     } else {
    +       cat("trend.order =", m1,
    +           "ar.order =", m2,
    +           "seasonal.order =", k,
    +           "AIC =", fit$aic, "\n")
    +     }
    +   }
    + }    
\end{Verbatim}
上記を実行すると下記のような結果が得られる。
\begin{Verbatim}[fontsize=\small, baselinestretch=0.9, frame=single]
    trend.order = 1 ar.order = 1 seasonal.order = 0 AIC = 35465.07 
    trend.order = 1 ar.order = 2 seasonal.order = 0 AIC = 35370.69 
    trend.order = 1 ar.order = 3 seasonal.order = 0 AIC = 35369.54 
    trend.order = 1 ar.order = 4 seasonal.order = 0 AIC = 35368.89 
    trend.order = 1 ar.order = 5 seasonal.order = 0 AIC = 35631.88 
    trend.order = 1 ar.order = 6 seasonal.order = 0 AIC = 35354.22 
    trend.order = 1 ar.order = 7 seasonal.order = 0 AIC = 35388.21 
    trend.order = 2 ar.order = 1 seasonal.order = 0 AIC = 35644.09 
    trend.order = 2 ar.order = 2 seasonal.order = 0 AIC = 35411.51 
    trend.order = 2 ar.order = 3 seasonal.order = 0 AIC = 35402.68 
    trend.order = 2 ar.order = 4 seasonal.order = 0 AIC = 35389.37 
    trend.order = 2 ar.order = 5 seasonal.order = 0 AIC = 35393.69 
    trend.order = 2 ar.order = 6 seasonal.order = 0 AIC = 35390.23 
    trend.order = 2 ar.order = 7 seasonal.order = 0 AIC = 35391.92 
    trend.order = 3 ar.order = 1 seasonal.order = 0 AIC = 35832.37 
    trend.order = 3 ar.order = 2 seasonal.order = 0 AIC = 35560.81 
    trend.order = 3 ar.order = 3 seasonal.order = 0 AIC = 35550.06 
    trend.order = 3 ar.order = 4 seasonal.order = 0 AIC = 35530.52 
    trend.order = 3 ar.order = 5 seasonal.order = 0 AIC = 35534.47 
    trend.order = 3 ar.order = 6 seasonal.order = 0 AIC = 35527.38 
    trend.order = 3 ar.order = 7 seasonal.order = 0 AIC = 35530.68    
\end{Verbatim}
上記の結果から、トレンド次数 = 1, AR次数 = 6の組み合わせがAIC = 35354.22で最小になった。よって、このモデルを採用する。

\section{decomp実行(仮)}

3.1節で決定したモデルを用いてdecomp関数を用いて〜する。
\begin{Verbatim}[fontsize=\small, baselinestretch=0.9, frame=single]
> dp <- decomp(nikkei_cl, trend.order = 1, ar.order = 6, seasonal.order = 0)
\end{Verbatim}
上記を実行すると下記のような結果が得られる。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/decomp_plot.png}
    \caption{decomp実行結果(仮)} 
    \label{fig:decomp} 
    \end{figure}

上記の結果から(考察)

\chapter{ARIMAモデルによる〜分析}



\chapter{おわりに} % <--ここに章のタイトルを入れる

()

\begin{thebibliography}{99} % 文献リストの作成

\bibitem{timsac}
The Institute of Statistical Mathematics (2023)
\textit{timsac: Time Series Analysis and Control Package},
URL: \url{https://cran.r-project.org/package=timsac}.

\bibitem{Janssens} Janssens, J. (2014) \textit{Data Science at the Command Line}, O'Reilly Media. 

(太田満久, 下田倫大, 増田泰彦監訳, 長尾高弘訳 (2015) 『コマンドラインではじめるデータサイエンス: 分析プロセスを自在に進めるテクニック』, オライリー・ジャパン.)

\bibitem{Jimichi2018-a} 地道正行 (2018-a)
『探索的財務ビッグデータ解析 --前処理、データラングリング、再現可能性--』, 
商学論究, 第66巻, 第1号, pp. 1-31, 
関西学院大学商学研究会. 

\bibitem{Jimichi2018-b} 地道正行 (2018-b) 
『探索的財務ビッグデータ解析 --データ可視化, 統計モデリング, モデル選択, モデル評価, 動的文書生成, 再現可能研究--』, 
商学論究, 第66巻, 第2号, pp. 1-41, 
関西学院大学商学研究会. 

\bibitem{Jimichi2018-c}
地道 正行 (2018-c)
『データサイエンスの基礎: R による統計学独習』, 
裳華房

\bibitem{Motohashi} 本橋智光 (2018)『前処理大全: データ分析のための SQL/R/Python 実践テクニック』, 技術評論社.

\bibitem{Nishida} 西田圭介 (2017)『ビッグデータを支える技術: 刻々とデータが脈打つ自動化の世界』, 技術評論社.

\bibitem{Tange} Tange, Ole, (2018) \textit{GNU Parallel 2018}, ISBN: 9781387509881, DOI: 10.5281/zenodo.1146014, URL: \url{https://doi.org/10.5281/zenodo.1146014}, Mar, 2018.

\bibitem{Wickham.et.al(2023)}
Wickham, H., M.~\c{C}etinkaya-Rundel, and G.~Grolemund, 
(2023)
\textit{R for Data Science: Import, Tidy, Transform, Visualize, and Model Data, 2nd edition}, 
O'Reilly. 

\end{thebibliography}

\section*{謝辞}

本研究に対して, 関学花子先生から適切なコメントを頂いたことに, 感謝の意を表する. 

\end{document}