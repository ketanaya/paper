\documentclass[uplatex,a4j,11pt,dvipdfmx]{ujreport}

\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{enumerate}
\usepackage{fancyvrb}
\usepackage{fvextra}
\usepackage{mdframed}
\makeatletter
\def\kcharparline#1{
    \newcounter{chr}
    \setcounter{chr}{#1}
    \@tempdima=\linewidth
    \advance\@tempdima by-\value{chr}zw
    \addtocounter{chr}{-1}
    \divide\@tempdima by \value{chr}
    \advance\kanjiskip by\@tempdima
    \advance\parindent by\@tempdima}
\def\lineparpage#1{
    \baselineskip=\textheight
    \divide\baselineskip by #1}
\makeatother


\renewcommand{\bibname}{参考文献}

\begin{document}

\kcharparline{40} % 一行の文字数
\lineparpage{25}  % 一頁の行数


\title{卒業論文 \\
日経平均株価の時系列分析}
\author{
関西学院大学 商学部 \\
26022435 宮崎綾平% <--ここに学生番号と氏名を入れる
}
\date{2025年12月02日} % <--ここに作成日を入れる. 
%\date{\today} % 


\maketitle % タイトルページの作成

\tableofcontents % 目次の作成

\chapter{はじめに}

()

\chapter{現状分析(仮)} %<--ここに章のタイトルを入れる
この章では、2015年から2024年までの過去10年分の日経平均株価のデータを取得し、時系列データの図示を行うことによって時系列データの
大まかな特徴を捉え、どのような解析を行うべきか方針をたてる。
\section{データの取得} % <--ここに節のタイトルを入れる
今回分析ではRのquantmodパッケージを使って下記のように記述することで、2015年から2024年の日経平均株価のデータを取得している。

\begin{Verbatim}[fontsize=\small, baselinestretch=0.9, frame=single]
> nikkei <- getSymbols(Symbols = "^N225", 
                       src = "yahoo",
                       from = "2015-01-01",
                       to = "2024-12-31",
                       auto.assign = FALSE)
\end{Verbatim}

\section{データの前処理}
この章では分析を行うためのデータの前処理を行う。まずはデータの列構造などについてhead関数を用いて確認する。
\begin{Verbatim}[fontsize=\small, baselinestretch=0.9, frame=single]
> head(nikkei)
           N225.Open N225.High N225.Low N225.Close N225.Volume N225.Adjusted
2015-01-05  17325.68  17540.92 17219.22   17408.71   116500000      17408.71
2015-01-06  17101.58  17111.36 16881.73   16883.19   166000000      16883.19
2015-01-07  16808.26  16974.61 16808.26   16885.33   138600000      16885.33
2015-01-08  17067.40  17243.71 17016.09   17167.10   140600000      17167.10
2015-01-09  17318.74  17342.65 17129.53   17197.73   155200000      17197.73
2015-01-13  16970.88  17087.71 16828.27   17087.71   149200000      17087.71
\end{Verbatim}

このデータには日付に加え、「N225.Open,N225.High,N225.Low,N225.Close,N225.Volume,\\N225.Adjusted」という列が存在し、それぞれ
「始値、高値、安値、終値、出来高、調整後終値」を意味する。今回の分析では、終値が当日の市場取引が全て完結した時点の値であるという観点から、
終値を分析対象とする。次に終値の列だけを抽出し、summary関数を用いてデータの概要を確認する。

\begin{Verbatim}[fontsize=\small, baselinestretch=0.9, frame=single]
> nikkei_cl <- Cl(nikkei)
> summary(nikkei_cl)
     Index              N225.Close   
 Min.   :2015-01-05   Min.   :14952  
 1st Qu.:2017-07-07   1st Qu.:20013  
 Median :2019-12-14   Median :22823  
 Mean   :2019-12-27   Mean   :24832  
 3rd Qu.:2022-06-28   3rd Qu.:28451  
 Max.   :2024-12-30   Max.   :42224  
                      NA's   :21           
\end{Verbatim}

上記の結果から、今回のデータでは終値は14952円から42224円の間で推移していることがわかった。
また、データが21個の欠測値を持つことがわかったため、これらの欠測値について検証する。

\begin{Verbatim}[fontsize=\small, baselinestretch=0.9, frame=single]
> na <- nikkei_cl[is.na(nikkei_cl)]
> na
           N225.Close
2017-07-17         NA
2017-08-11         NA
2017-09-18         NA
2017-10-09         NA
2017-11-03         NA
2017-11-23         NA
2018-01-01         NA
2018-01-02         NA
2018-01-03         NA
2018-01-08         NA
2018-02-12         NA
2018-03-21         NA
2018-04-30         NA
2018-05-03         NA
2018-05-04         NA
2018-09-17         NA
2018-09-24         NA
2018-10-08         NA
2018-11-23         NA
2018-12-24         NA
2018-12-31         NA
> nikkei_cl <- na.omit(nikkei_cl)
\end{Verbatim}

上記の結果をもとに、欠測値が記録されている日付について調べると、全て祝日であることがわかった。
東京証券取引所は祝日は取引を行っていないため、これらの欠測値を含んだ列は分析に不要と考え、na.omit関数によってデータから取り除く処理を行う。

\section{時系列データの図示}
2.2節で前処理を行った時系列データを用い、観測地点を横軸に、観測値を縦軸にとり隣り合う観測値を直線で結んだ図を描く。
この図を描くことで、時系列データが\emph{トレンド}や\emph{季節性}を含むかをどうかを可視化することができる。なお、トレンドと季節性について定義を
\cite{Hyndman}から引用する。
\begin{itemize}
    \item トレンド
    \begin{itemize}
    \item A trend exists when there is a long-term increase or decrease in the data.
     It does not have to be linear. Sometimes we will refer to a trend as “changing direction”, 
     when it might go from an increasing trend to a decreasing trend. 
    \end{itemize}
\end{itemize}    

\begin{itemize}
    \item 季節性
    \begin{itemize}
    \item A seasonal pattern occurs when a time series is affected by seasonal factors such as 
    the time of the year or the day of the week. 
    Seasonality is always of a fixed and known period. 
    \end{itemize}
\end{itemize}   

これらを踏まえた上で、時系列データの図示を行ったところ、図 \ref{fig:nikkei-cl} のような結果になった。
この図からこのデータは上昇トレンドがあることが見て取れる。また、季節性に関しては図を見る限り、確認することはできない。
加えて、値が急激に変化している地点についても調査を行った。2020年の2月から3月にかけて値の急激な減少の後に、急上昇をしている地点が存在する。
この原因はコロナによる経済活動の停滞及び、それを受けた日銀の金融政策に対する期待である。また、2024年の1月頃に値が急上昇している地点がある。
この原因はNVIDIAが市場を上回る好決算を発表したことで、東京市場の半導体関連株が買われたことによるものである。
なお、これらは\cite{nikkei-1},\cite{nikkei-2}を参照している。

\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\linewidth]{figures/nikkei_plot}
\caption{日経平均株価(終値)の推移} 
\label{fig:nikkei-cl} 
\end{figure}

\section{時系列データの自己相関}

図 \ref{fig:acf} は、データの自己相関をプロットしたものである。詳細な自己相関係数についても確認できる。(ここに考察)

\begin{figure}[htbp] %何故か図がコードブロックに入り込んでる
    \centering
    \includegraphics[width=0.9\linewidth]{figures/acf}
    \caption{日経平均株価(終値)の自己相関} 
    \label{fig:acf} 
    \end{figure}

\begin{Verbatim}[fontsize=\small, baselinestretch=0.9, frame=single]
> acf(nikkei_cl, plot = FALSE)
Autocorrelations of series ‘nikkei_cl’, by lag

    0     1     2     3     4     5     6     7     8     9    10    11    12 
1.000 0.997 0.994 0.992 0.989 0.986 0.984 0.981 0.979 0.976 0.974 0.972 0.969 
   13    14    15    16    17    18    19    20    21    22    23    24    25 
0.967 0.964 0.962 0.960 0.957 0.955 0.953 0.951 0.949 0.947 0.945 0.943 0.941 
   26    27    28    29    30    31    32    33 
0.939 0.937 0.935 0.933 0.931 0.929 0.927 0.924 
\end{Verbatim}

\chapter{平方根フィルタを用いた非定常時系列データの構成成分分解(仮)}

\section{decompについて(仮)}
(decompをやる目的)、を検証するために本研究ではTIMSACパッケージのdecomp関数を使用する。decomp関数とは()を行うための関数である。
具体的には以下のモデル式を使用する


\begin{equation}
y(t) = T(t) + AR(t) + S(t) + TD(t) + W(t)
\end{equation} 

ここで、T(t)はトレンド成分、AR(t)はAR成分、S(t)は季節成分、TD(t)は曜日効果成分、W(t)は観測ノイズである。
なお, これらは \cite{timsac} を参照している。
今回のデータはxtsオブジェクトのため〜なため、季節成分は除外して考える。また、曜日効果成分も〜という理由から除外して考える。
次にトレンド成分、AR成分の次数を決定するために、AIC(赤池情報量基準, Akaike's Information Criterion)を用いる。(AICの説明)
ここで、timsacパッケージを用いて、トレンド成分の次数を1,2,3、AR成分の次数を1~7に設定し、全ての組み合わせのAICを求めた。これらの組み合わせの中で最もAICが小さい
モデルを採用する。
\begin{Verbatim}[fontsize=\small, baselinestretch=0.9, frame=single]
    > library(timsac)
    > y <- nikkei_cl
    > 
    > for (m1 in 1:3) {
    +   for (m2 in 1:7) {
    +     k <- 0
    +     
    +     fit <- try(
    +       decomp(
    +         y,
    +         trend.order    = m1,
    +         ar.order       = m2,
    +         seasonal.order = k,
    +         plot           = FALSE
    +       ),
    +       silent = TRUE
    +     )
    +     
    +     if (inherits(fit, "try-error")) {
    +       cat("[ERROR]",
    +           "trend.order =", m1,
    +           "ar.order =", m2,
    +           "seasonal.order =", k,
    +           "AIC = NA\n")
    +     } else {
    +       cat("trend.order =", m1,
    +           "ar.order =", m2,
    +           "seasonal.order =", k,
    +           "AIC =", fit$aic, "\n")
    +     }
    +   }
    + }    
\end{Verbatim}
上記を実行すると下記のような結果が得られる。
\begin{Verbatim}[fontsize=\small, baselinestretch=0.9, frame=single]
    trend.order = 1 ar.order = 1 seasonal.order = 0 AIC = 35465.07 
    trend.order = 1 ar.order = 2 seasonal.order = 0 AIC = 35370.69 
    trend.order = 1 ar.order = 3 seasonal.order = 0 AIC = 35369.54 
    trend.order = 1 ar.order = 4 seasonal.order = 0 AIC = 35368.89 
    trend.order = 1 ar.order = 5 seasonal.order = 0 AIC = 35631.88 
    trend.order = 1 ar.order = 6 seasonal.order = 0 AIC = 35354.22 
    trend.order = 1 ar.order = 7 seasonal.order = 0 AIC = 35388.21 
    trend.order = 2 ar.order = 1 seasonal.order = 0 AIC = 35644.09 
    trend.order = 2 ar.order = 2 seasonal.order = 0 AIC = 35411.51 
    trend.order = 2 ar.order = 3 seasonal.order = 0 AIC = 35402.68 
    trend.order = 2 ar.order = 4 seasonal.order = 0 AIC = 35389.37 
    trend.order = 2 ar.order = 5 seasonal.order = 0 AIC = 35393.69 
    trend.order = 2 ar.order = 6 seasonal.order = 0 AIC = 35390.23 
    trend.order = 2 ar.order = 7 seasonal.order = 0 AIC = 35391.92 
    trend.order = 3 ar.order = 1 seasonal.order = 0 AIC = 35832.37 
    trend.order = 3 ar.order = 2 seasonal.order = 0 AIC = 35560.81 
    trend.order = 3 ar.order = 3 seasonal.order = 0 AIC = 35550.06 
    trend.order = 3 ar.order = 4 seasonal.order = 0 AIC = 35530.52 
    trend.order = 3 ar.order = 5 seasonal.order = 0 AIC = 35534.47 
    trend.order = 3 ar.order = 6 seasonal.order = 0 AIC = 35527.38 
    trend.order = 3 ar.order = 7 seasonal.order = 0 AIC = 35530.68    
\end{Verbatim}
上記の結果から、トレンド次数 = 1, AR次数 = 6の組み合わせがAIC = 35354.22で最小になった。よって、このモデルを採用する。

\section{decomp実行(仮)}

3.1節で決定したモデルを用いてdecomp関数を用いて〜する。
\begin{Verbatim}[fontsize=\small, baselinestretch=0.9, frame=single]
> dp <- decomp(nikkei_cl, trend.order = 1, ar.order = 6, seasonal.order = 0)
\end{Verbatim}
上記を実行すると下記のような結果が得られる。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/decomp_plot.png}
    \caption{decomp実行結果(仮)} 
    \label{fig:decomp} 
    \end{figure}

上記の結果から(考察)

\chapter{ARIMAモデルによる〜分析}
\section{ARIMAモデルについて}
\section{モデル化の手順}
非季節性時系列データにARIMAモデルを適合する際は、下記の手順を実施する。なお, これらは \cite{Hyndman} を参照している。
1.データをプロットして、異常値を特定する。
2.必要なら、(Box-Cox変換を使って)データを変換し、分散を安定化させる。
3.データが非定常なら、定常になるまでデータの一つ目差分を取る。
4.ACF/PACFを検討する: ARIMA( p,d,0)モデルとARIMA( 0,d,q)モデルのどちらが適切か？
5.選んだモデルを試す、そして、AICcを使ってより良いモデルを探索する。
6.選んだモデルからの残差を、ACFプロットやportmanteau検定でチェックする。残差がホワイトノイズらしくなければ、モデルを修正して試す。
7.残差がホワイトノイズらしく見えるようになったら、予測を計算する。
\section{モデル化}
モデル化はfableパッケージのauto.arimaを使う。
\section{モデルの評価}
\section{予測と考察}



\chapter{おわりに} % <--ここに章のタイトルを入れる

()

\begin{thebibliography}{99} % 文献リストの作成

\bibitem{timsac}
The Institute of Statistical Mathematics (2023)
\textit{timsac: Time Series Analysis and Control Package},
URL: \url{https://cran.r-project.org/package=timsac}.

\bibitem{Hyndman} 
Hyndman, R.J., \& Athanasopoulos, G. (2021)
\textit{Forecasting: principles and practice, 3rd edition},
OTexts: Melbourne, Australia. 
URL: \url{https://otexts.com/fpp3/}. 
Accessed on 2 December 2025

\bibitem{Kitagawa} 北川源四郎 (2020) 
『Rによる時系列モデリング入門』,
岩波書店

\bibitem{nikkei-1} 
日本経済新聞, (10 April 2020),
『日経平均、3月は記録ずくめ新型コロナで変動大きく: 株式投資の超キホン日経平均を知ろう!(17)』,
URL: \url{https://www.nikkei.com/article/DGXMZO57807450Y0A400C2I00000/}

\bibitem{nikkei-2} 
日本経済新聞, (22 February 2024),
『日経平均、終値3万9098円　34年ぶり最高値更新』,
URL: \url{https://www.nikkei.com/article/DGXZQOFL220S70S4A220C2000000/}

\bibitem{Janssens} Janssens, J. (2014) \textit{Data Science at the Command Line}, O'Reilly Media. 

(太田満久, 下田倫大, 増田泰彦監訳, 長尾高弘訳 (2015) 『コマンドラインではじめるデータサイエンス: 分析プロセスを自在に進めるテクニック』, オライリー・ジャパン.)

\bibitem{Jimichi2018-a} 地道正行 (2018-a)
『探索的財務ビッグデータ解析 --前処理、データラングリング、再現可能性--』, 
商学論究, 第66巻, 第1号, pp. 1-31, 
関西学院大学商学研究会. 

\bibitem{Jimichi2018-b} 地道正行 (2018-b) 
『探索的財務ビッグデータ解析 --データ可視化, 統計モデリング, モデル選択, モデル評価, 動的文書生成, 再現可能研究--』, 
商学論究, 第66巻, 第2号, pp. 1-41, 
関西学院大学商学研究会. 

\bibitem{Jimichi2018-c}
地道 正行 (2018-c)
『データサイエンスの基礎: R による統計学独習』, 
裳華房

\bibitem{Motohashi} 本橋智光 (2018)『前処理大全: データ分析のための SQL/R/Python 実践テクニック』, 技術評論社.

\bibitem{Nishida} 西田圭介 (2017)『ビッグデータを支える技術: 刻々とデータが脈打つ自動化の世界』, 技術評論社.

\bibitem{Tange} Tange, Ole, (2018) \textit{GNU Parallel 2018}, ISBN: 9781387509881, DOI: 10.5281/zenodo.1146014, URL: \url{https://doi.org/10.5281/zenodo.1146014}, Mar, 2018.

\bibitem{Wickham.et.al(2023)}
Wickham, H., M.~\c{C}etinkaya-Rundel, and G.~Grolemund, 
(2023)
\textit{R for Data Science: Import, Tidy, Transform, Visualize, and Model Data, 2nd edition}, 
O'Reilly. 

\end{thebibliography}

\section*{謝辞}

本研究に対して, 関学花子先生から適切なコメントを頂いたことに, 感謝の意を表する. 

\end{document}